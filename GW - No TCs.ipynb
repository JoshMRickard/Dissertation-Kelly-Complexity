{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66220e39",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import itertools\n",
    "import dill\n",
    "import missingno\n",
    "from rff import RFF\n",
    "from backtest import Backtest\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.metrics import r2_score, precision_score, recall_score, accuracy_score\n",
    "from matplotlib import rc\n",
    "pd.options.mode.chained_assignment = None  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cfd5a3",
   "metadata": {},
   "source": [
    "# Load Environment (preloads results, optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffdf87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.load_session('GWNOTCs.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111ebc7",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be193b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"b/m\", \"de\", \"dfr\", \"dfy\", \"dp\", \"dy\", \"ep\", \"infl\", \"ltr\", \"lty\", \"ntis\", \"svar\", \"tbl\", \"tms\", \"returns\"]\n",
    "nber = pd.read_csv(\"data/NBER_20210719_cycle_dates_pasted.csv\")[1:]\n",
    "nber[\"peak\"] = pd.to_datetime(nber[\"peak\"])\n",
    "nber[\"trough\"] = pd.to_datetime(nber[\"trough\"])\n",
    "data_raw = pd.read_csv(\"data/PredictorData2021 - Monthly.csv\")\n",
    "data_raw[\"yyyymm\"] = pd.to_datetime(data_raw[\"yyyymm\"], format='%Y%m', errors='coerce')\n",
    "data_raw[\"Index\"] = data_raw[\"Index\"].str.replace(\",\", \"\")\n",
    "data_raw = data_raw.set_index(\"yyyymm\")\n",
    "data_raw[data_raw.columns] = data_raw[data_raw.columns].astype(float)\n",
    "data_raw = data_raw.rename({\"Index\":\"prices\"}, axis=1)\n",
    "data_raw[\"dfy\"] = data_raw[\"BAA\"] - data_raw[\"AAA\"]\n",
    "data_raw[\"tms\"] = data_raw[\"lty\"] - data_raw[\"tbl\"]\n",
    "data_raw[\"de\"] = np.log(data_raw[\"D12\"]) - np.log(data_raw[\"E12\"])\n",
    "data_raw[\"dfr\"] = data_raw[\"corpr\"] - data_raw[\"ltr\"]\n",
    "data_raw[\"lag_price\"] = data_raw[\"prices\"].shift()\n",
    "data_raw[\"dp\"] = np.log(data_raw[\"D12\"]) - np.log(data_raw[\"prices\"])\n",
    "data_raw[\"dy\"] = np.log(data_raw[\"D12\"]) - np.log(data_raw[\"lag_price\"])\n",
    "data_raw[\"ep\"] = np.log(data_raw[\"E12\"])  - np.log(data_raw[\"prices\"])\n",
    "data_raw[\"returns\"] = data_raw[\"prices\"].pct_change()\n",
    "returns = data_raw[\"returns\"].copy()\n",
    "data = data_raw[COLUMNS].dropna()\n",
    "returns = returns[returns.index.isin(data.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9b09c",
   "metadata": {},
   "source": [
    "# Standardise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca4e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in COLUMNS:\n",
    "    data[col] = (data[col] - data[col].expanding(36).mean())/data[col].expanding(36).std()\n",
    "returns_std = returns.rolling(12).std().shift()\n",
    "returns = returns / returns_std\n",
    "data = data[36:]\n",
    "returns = returns[36:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38019f",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2c1f3",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 12 #window\n",
    "gammas = [0.1, 0.5, 1, 2, 4, 8, 16] #bandwidth parameter\n",
    "z_values = list(np.logspace(-3, 3, 7)) #shrinkage\n",
    "\n",
    "C_values = (\n",
    "    list(np.logspace(-1, 0, 25, base=10)) +\n",
    "    list(np.logspace(0, 1, 25, base=10)) +\n",
    "    list(np.logspace(1, 2, 25, base=10)) +\n",
    "    list(np.logspace(2, 3, 25, base=10))\n",
    ") #logscale\n",
    "\n",
    "P_values = [c*T for c in C_values] #no of features, creates double number listed as uses sin + cos\n",
    "P_values = list({2*round(P/2) for P in P_values})\n",
    "P_values.sort()\n",
    "\n",
    "#control for seed\n",
    "iterations = list(np.arange(1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def simulation(data, returns, gamma, P, z, iteration):\n",
    "    c = P/T\n",
    "    rff_data = RFF(n=int(P/2), gamma=gamma).features(data, seed=iteration)\n",
    "    sim = Backtest(z=z, T=T).predict(X=rff_data, y=returns.shift(-1))\n",
    "    performance = sim.performance()\n",
    "    performance.update({\"gamma\": gamma, \"P\": P, \"z\": z, \"c\": c, \"T\": T, \"iteration\": iteration})\n",
    "    return performance\n",
    "metrics = Parallel(n_jobs=-1)(delayed(simulation)(data, returns, gamma, P, z, iteration = seed) for gamma, P, z, seed in itertools.product(gammas, P_values, z_values, iterations))\n",
    "metrics = pd.DataFrame(metrics)\n",
    "metrics_mean = metrics.groupby([\"gamma\", \"P\", \"z\", \"c\", \"T\"]).mean().reset_index().drop(\"iteration\", axis=1)\n",
    "metrics_mean[\"log10(z)\"] = np.log10(metrics_mean[\"z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a59ba4",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906dc82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = metrics_mean[(metrics_mean.gamma==0.5) & (metrics_mean.z==1000) & (metrics_mean.c == 1)][[\"Expected Return\", \"Volatility\", \"R2\", \"SR\", \"IR\"]].max().to_dict()\n",
    "#change result parameters to see performance of specific model specification\n",
    "\n",
    "print(\"Our Results:\")\n",
    "for k,v in result.items():\n",
    "    print(f\"\\t - {k}: {v}\")\n",
    "\n",
    "#export results\n",
    "complexityall = metrics_mean[[\"c\",\"z\", \"gamma\",\"Expected Return\", \"Volatility\", \"R2\", \"SR\", \"IR\"]]\n",
    "complexityall.to_csv(\"complexityall.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd7eb73",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate tex backend for LaTeX graphs\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 24})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b15b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma in [0.5, 2]:\n",
    "    result = metrics_mean[metrics_mean[\"gamma\"]==gamma]\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize = (6,3), width_ratios = [3,1])\n",
    "    result.set_index(\"c\").groupby(\"log10(z)\")[\"SR\"].plot(ax = ax1)\n",
    "    result.set_index(\"c\").groupby(\"log10(z)\")[\"SR\"].plot(ax = ax2)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "    ax1.set_xlim(0,100)\n",
    "    ax2.set_xlim(990,1000)\n",
    "    ax1.axvline(x=100, linestyle=\"--\", c=\"black\")\n",
    "    ax2.axvline(x=990, linestyle=\"--\", c=\"black\")\n",
    "    ax2.yaxis.tick_right()\n",
    "    d = .015 \n",
    "    kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "    ax1.plot((1-d,1+d), (-d,+d), **kwargs)\n",
    "    ax1.plot((1-d,1+d),(1-d,1+d), **kwargs)\n",
    "    kwargs.update(transform=ax2.transAxes)\n",
    "    ax2.plot((-d,+d), (1-d,1+d), **kwargs)\n",
    "    ax2.plot((-d,+d), (-d,+d), **kwargs)\n",
    "    ax2.legend(loc=\"upper left\", title=\"log10(z)\", bbox_to_anchor=(1.4, 1.04))\n",
    "    fig.add_subplot(ax1)\n",
    "    fig.add_subplot(ax2)\n",
    "    ax1.set_ylabel(\"SR\")\n",
    "    if gamma == 0.5:\n",
    "        ax1.set_xlabel('')\n",
    "        ax2.set_xlabel('')\n",
    "    fig.suptitle(f\"gamma = {gamma}\")\n",
    "    fig.savefig(f\"ER{gamma}NOTCs.pdf\", dpi = 1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696c5bd",
   "metadata": {},
   "source": [
    "# Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2089be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(12,7))\n",
    "fig.delaxes(axs[2,1])\n",
    "fig.delaxes(axs[2,2])\n",
    "axs = axs.flatten()\n",
    "for i, gamma in enumerate(metrics_mean[\"gamma\"].unique()):\n",
    "    metrics_mean[metrics_mean[\"gamma\"]==gamma].set_index(\"c\").groupby(\"log10(z)\")[\"SR\"].plot(ax=axs[i], title=f\"gamma={gamma}\")\n",
    "    axs[i].set_xscale('log')\n",
    "    axs[i].set_xlabel('')\n",
    "    axs[i].set_ylim(-0.05, 0.5)\n",
    "    if gamma not in [0.1, 2, 16]:\n",
    "        axs[i].set_yticks([])\n",
    "axs[4].legend(loc=\"upper left\", title=\"log10(z)\", bbox_to_anchor=(1, 1.05))\n",
    "fig.delaxes(axs[5])\n",
    "fig.canvas.draw()\n",
    "plt.tight_layout(pad = -4.5)\n",
    "plt.savefig(\"GWNOTCGAMMA.pdf\", dpi = 1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8b215",
   "metadata": {},
   "source": [
    "# Market Timing positions vs NBER Recessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949721c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_average_lists(nested_lists):\n",
    "    sum_list = [0] * len(nested_lists[0])\n",
    "    for nested_list in nested_lists:\n",
    "        for i, value in enumerate(nested_list):\n",
    "            sum_list[i] += value\n",
    "    num_nested_lists = len(nested_lists)\n",
    "    averaged_list = [sum_value / num_nested_lists for sum_value in sum_list]\n",
    "    return averaged_list\n",
    "\n",
    "##############################################################\n",
    "\n",
    "backtest_1 = []\n",
    "rff_data_1 = RFF(n=6000, gamma=0.5).features(data)\n",
    "for a in range(1,100):\n",
    "    backtest_temp_1 = Backtest(z=10**3, T=12).predict(X=rff_data_1, y=returns.shift(-1))\n",
    "    backtest_temp_1 = backtest_temp_1.backtest\n",
    "    backtest_1.append(backtest_temp_1)\n",
    "\n",
    "timing_strategy_avg_1 = []\n",
    "for b in range(1, len(backtest_1)):\n",
    "    timing_strategy_avg_1.append(backtest_1[b][\"timing_strategy\"])\n",
    "    \n",
    "averaged_list_1 = merge_and_average_lists(timing_strategy_avg_1)\n",
    "index_list_1 = backtest_1[1][\"timing_strategy\"].index\n",
    "averaged_series_1 = pd.Series(averaged_list_1, index=index_list_1)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "backtest_2= []\n",
    "rff_data_2 = RFF(n=6000, gamma=2).features(data)\n",
    "for a in range(1,100):\n",
    "    backtest_temp_2 = Backtest(z=10**3, T=12).predict(X=rff_data_2, y=returns.shift(-1))\n",
    "    backtest_temp_2 = backtest_temp_2.backtest\n",
    "    backtest_2.append(backtest_temp_2)\n",
    "\n",
    "timing_strategy_avg_2 = []\n",
    "for b in range(1, len(backtest_2)):\n",
    "    timing_strategy_avg_2.append(backtest_2[b][\"timing_strategy\"])\n",
    "    \n",
    "averaged_list_2 = merge_and_average_lists(timing_strategy_avg_2)\n",
    "index_list_2 = backtest_2[1][\"timing_strategy\"].index\n",
    "averaged_series_2 = pd.Series(averaged_list_2, index=index_list_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f7c00",
   "metadata": {},
   "source": [
    "## MT Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec7696f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "R[write to console]: \u001b[1mindexing\u001b[0m \u001b[34mbacktest_1.csv\u001b[0m [===================================] \u001b[32m2.15GB/s\u001b[0m, eta: \u001b[36m 0s\u001b[0m\n",
      "                                                                                                                   \n",
      "R[write to console]: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m1093\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36m--\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m------------------------------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m  (3): forecast, timing_strategy, market_return\n",
      "\u001b[34mdate\u001b[39m (1): index\n",
      "\n",
      "\u001b[36mi\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mi\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "TM =  -0.5595266 \n",
      "HM =  0.4041364 \n"
     ]
    }
   ],
   "source": [
    "backtest_1[1][\"timing_strategy\"] = averaged_series_1\n",
    "backtest_1[1].to_csv(\"backtest_1.csv\")\n",
    "\n",
    "from rpy2 import robjects\n",
    "robjects.r(''' if (!require(\"pacman\")) install.packages(\"pacman\")\n",
    "pacman::p_load(tidyverse, lubridate, readr, timetk, tidyquant,\n",
    "               broom, xts, PerformanceAnalytics, tibbletime,\n",
    "               tidymodels, data.table)\n",
    "setwd(\"C:/Users/Josh/OneDrive - University of Cambridge/Dissertation/replicating_the_virtue_of_complexity_in_machine_learning_portfolios-main/replicating_the_virtue_of_complexity_in_machine_learning_portfolios-main\")\n",
    "\n",
    "backtest = read_csv(\"backtest_1.csv\")\n",
    "\n",
    "backtest = backtest %>%\n",
    "  tk_xts(select = -index, date_var = index)\n",
    "\n",
    "portfolio = backtest$timing_strategy\n",
    "benchmark = backtest$market_return\n",
    "benchmark_sq = benchmark^2\n",
    "\n",
    "reg_TM = lm(portfolio ~ benchmark + benchmark_sq)\n",
    "results_TM = summary(reg_TM)\n",
    "cat(\"TM = \", results_TM[[\"coefficients\"]][3,3], \"\\n\")\n",
    "\n",
    "D = pmax(0, -benchmark)\n",
    "reg_HM = lm(portfolio ~ benchmark + D)\n",
    "results_HM = summary(reg_HM)\n",
    "cat(\"HM = \", results_HM[[\"coefficients\"]][3,3], \"\\n\")\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f8c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "R[write to console]: \u001b[1mindexing\u001b[0m \u001b[34mbacktest_2.csv\u001b[0m [===================================] \u001b[32m2.15GB/s\u001b[0m, eta: \u001b[36m 0s\u001b[0m\n",
      "                                                                                                                   \n",
      "R[write to console]: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m1093\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36m--\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m------------------------------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m  (3): forecast, timing_strategy, market_return\n",
      "\u001b[34mdate\u001b[39m (1): index\n",
      "\n",
      "\u001b[36mi\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mi\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "TM =  1.891048 \n",
      "HM =  2.425232 \n"
     ]
    }
   ],
   "source": [
    "backtest_2[1][\"timing_strategy\"] = averaged_series_2\n",
    "backtest_2[1].to_csv(\"backtest_2.csv\")\n",
    "\n",
    "from rpy2 import robjects\n",
    "robjects.r(''' if (!require(\"pacman\")) install.packages(\"pacman\")\n",
    "pacman::p_load(tidyverse, lubridate, readr, timetk, tidyquant,\n",
    "               broom, xts, PerformanceAnalytics, tibbletime,\n",
    "               tidymodels, data.table)\n",
    "setwd(\"C:/Users/Josh/OneDrive - University of Cambridge/Dissertation/replicating_the_virtue_of_complexity_in_machine_learning_portfolios-main/replicating_the_virtue_of_complexity_in_machine_learning_portfolios-main\")\n",
    "\n",
    "backtest = read_csv(\"backtest_2.csv\")\n",
    "\n",
    "backtest = backtest %>%\n",
    "  tk_xts(select = -index, date_var = index)\n",
    "\n",
    "portfolio = backtest$timing_strategy\n",
    "benchmark = backtest$market_return\n",
    "benchmark_sq = benchmark^2\n",
    "\n",
    "reg_TM = lm(portfolio ~ benchmark + benchmark_sq)\n",
    "results_TM = summary(reg_TM)\n",
    "cat(\"TM = \", results_TM[[\"coefficients\"]][3,3], \"\\n\")\n",
    "\n",
    "D = pmax(0, -benchmark)\n",
    "reg_HM = lm(portfolio ~ benchmark + D)\n",
    "results_HM = summary(reg_HM)\n",
    "cat(\"HM = \", results_HM[[\"coefficients\"]][3,3], \"\\n\")\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf4d384",
   "metadata": {},
   "source": [
    "# WILL RESET ENVIRONMENT SAVE IF RUN, BE CAREFUL ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160402c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('GWNOTCs.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
